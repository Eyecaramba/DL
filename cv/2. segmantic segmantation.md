*INTRO*   
segmantic segmantation 

<br>
<br>

__목차__  
1. segmantic segmantation 
2. fully convolutional networks
3. U-Net
4. DeepLab


## 1. segmantic segmantation 문제 
___
segmantic segmantation이란 이미지의 픽셀단위로 라벨을 분류하는 문제를 말한다.  

다른 종류의 물체는 다르게 분류하지만 같은 종류의 다른 물체들은 다르게 분류하지는 않는다.  




## 2. fully convonlutional networks 
___
1. FCN의 장점    
    - image classification 문제에서는 모델 마지막 단에 fc layer를 사용하여 분류를 진행하였다.  
    그러나 fc layer는 output의 크기가 고정되어 있기 때문에 다양한 사이즈의 이미지를 픽셀 단위로 분류하는데 적합한 구조는 아니다.  
    또한 convolution layer에서 fc layer로 넘어가면서 가지고 있었던 공간 정보가 사라지기 때문에 픽셀 단위로 분류하기 적합하지 않다.  
    - 반면 fully convolutional networks는 output의 크기가 유연하게 변할 수 있고 공간 정보 또한 계속해서 유지하기 때문에 segmantic segmantation 문제를 해결하기에 더 적합하다.    

<br>
  
2. FCN의 구조 
    - convolution 단계 
    - upsampling 단계 : convolution단계를 거치면서 낮아진 해상도를 다시 원래 input 이미지 사이즈로 복구하는 과정  
    upsampling은 다음과 같은 방법이 있다. 
    
            Transposed convolution  
            NN-size convolution   
            bilinear upsampling  
            trilinear upsampling  
            
    - hypercolumn

    



## 3. U-Net
___
...


## 4. DeepLab
___
...




## Ref
---
https://dennybritz.com/posts/deep-learning-ideas-that-stood-the-test-of-time/ 

5개의 module

convoltui
acti
drop
pooling

# 순서가 중요하지 않다.
conv -> batchnorm(정규분포) -> activation() -> drop -> pooling 

논문을 많이 구현해봤는가. 코드를 

Pooling은 중요한 것만 고르는 것이 목적이다.  
dropout을 activation 뒤에 둔다면 sigmoid는 0에서 0.5로 올라온다. 
activation 이후에 신호가 살아나게 됨으로 문제가 발생할 수 있다.  

batchnormalizatioin이 
데이터가 적은 경우는 batch norm의 

transfer learning  

뭐가 유사한가? 


task기반으로 learning이 

task를 구성하기 위해서는 어떤 것이 필요한가?


dataset과 label 그리고 evaluation matric으로 task를 정의할 수 있다.  

dataset과 matric이 

카카오에서는 batchsize와 learningrate의 관계에 대해 설명해주세요 

대학원에서 하나를 

유사한 곳에서 dataset이 sample이 되거나 evalution matric이 
dataset을 sampling되는 원천이 같은 곳

평가지표가 유사하고 dataset의 evalution이 
image 분류 task 


funcdamental한 내용을 더 짚고 넘어가야 한다.  
다음주는 universal appromaximatopr theorm 

hypterbolic tanh

lstm 모델안에서 hypter bolic tanh sigmoid 
activaion이 쓰이는 것이 